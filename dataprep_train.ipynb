{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9403327,"sourceType":"datasetVersion","datasetId":5704549}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\nimport numpy as np\nimport re \nimport torch\nfrom transformers import BlipProcessor, BlipForConditionalGeneration\nconversion_to_tons = {'gram': 1e-6,'ton': 1,'kilogram': 0.001,'ounce': 2.8349523125e-5,'pound': 0.00045359237,'carat': 2e-7,'microgram': 1e-12,'milligram': 1e-9 }\n\ndef convert_to_tons(row):\n    try:\n        value, unit = row['entity_value'].lower().split(' ', 1)\n        value = float(value)\n        conversion_factor = conversion_to_tons.get(unit.strip(), 1)\n        return value * conversion_factor\n    except ValueError:\n        return None  \n\nweight_units = ['gram', 'ton', 'kilogram', 'ounce', 'pound', 'carat', 'microgram', 'milligram']\n\ntrain_df = pd.read_csv('/kaggle/input/amazon24/train.csv')\nentity_name = 'item_weight'\nentity_df = train_df[train_df['entity_name'] == entity_name].copy()\n\nentity_df = entity_df.dropna(subset=['entity_value'])\nentity_df = entity_df[~entity_df['entity_value'].str.contains(r'\\[|\\bto\\b|\\be\\+17\\b', regex=True, na=False)]\nentity_df = entity_df[entity_df['entity_value'].str.contains('|'.join(weight_units), case=False, na=False)]\n\nentity_df['entity_value'] = entity_df.apply(convert_to_tons, axis=1)\nentity_df = entity_df[(entity_df['entity_value'] > 5e-8) & (entity_df['entity_value'] < 1)]\nentity_df = entity_df.dropna(subset=['entity_value'])\nentity_df = entity_df.iloc[:1500]\n\n\noriginal_df = entity_df\n\nblip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\nblip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n\ndef generate_caption(image_url):\n    response = requests.get(image_url)\n    image = Image.open(BytesIO(response.content)).convert('RGB')\n    inputs = blip_processor(images=image, return_tensors=\"pt\")\n    with torch.no_grad():\n        output = blip_model.generate(**inputs, max_new_tokens=20)\n    caption = blip_processor.decode(output[0], skip_special_tokens=True)\n    words = caption.split()\n    cleaned_words = [words[i] for i in range(len(words)) if i == 0 or words[i] != words[i-1]]\n    return ' '.join(cleaned_words)\n\nnew_data = []\n\nfor i in range(len(entity_df)):\n    print(f\"Processing {i + 1} of {len(entity_df)}\")\n    row = entity_df.iloc[i]\n    image_url = row['image_link']\n    entity_value = row['entity_value']\n    \n    caption = generate_caption(image_url)\n    \n    new_data.append({\n        'image_link': image_url,\n        'entity_value': entity_value,\n        'caption': caption\n    })\nnew_df = pd.DataFrame(new_data)\nnew_df.to_csv('new_dataframe_with_captions.csv', index=False)\n\nprint(\"New DataFrame created and saved to 'new_dataframe_with_captions.csv'\")\nprint(\"Columns in the new DataFrame:\", new_df.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2024-09-15T10:19:59.937977Z","iopub.execute_input":"2024-09-15T10:19:59.938446Z","iopub.status.idle":"2024-09-15T10:22:07.889479Z","shell.execute_reply.started":"2024-09-15T10:19:59.938394Z","shell.execute_reply":"2024-09-15T10:22:07.887611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}