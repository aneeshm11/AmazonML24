{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T18:24:41.227808Z","iopub.status.busy":"2024-09-15T18:24:41.227088Z","iopub.status.idle":"2024-09-15T18:24:46.645418Z","shell.execute_reply":"2024-09-15T18:24:46.644537Z","shell.execute_reply.started":"2024-09-15T18:24:41.227738Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import DistilBertTokenizer, DistilBertModel\n","import torch.nn as nn\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from tqdm import tqdm\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T18:24:46.648198Z","iopub.status.busy":"2024-09-15T18:24:46.647367Z","iopub.status.idle":"2024-09-15T18:24:46.660495Z","shell.execute_reply":"2024-09-15T18:24:46.659216Z","shell.execute_reply.started":"2024-09-15T18:24:46.648153Z"},"trusted":true},"outputs":[],"source":["\n","class ItemDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len=50):\n","        self.dataframe = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        row = self.dataframe.iloc[idx]\n","        text = row['caption']\n","        label = row['entity_value']\n","\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'input_ids': inputs['input_ids'].squeeze(),\n","            'attention_mask': inputs['attention_mask'].squeeze(),\n","            'label': torch.tensor(label, dtype=torch.float)\n","        }\n","\n","class DistilBERTRegressor(nn.Module):\n","    def __init__(self, output_dim=1):\n","        super(DistilBERTRegressor, self).__init__()\n","        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n","        self.fc = nn.Linear(self.distilbert.config.hidden_size, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, output_dim)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.distilbert(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask\n","        )\n","        last_hidden_state = outputs[0]\n","        pooled_output = torch.mean(last_hidden_state, 1)\n","        x = pooled_output\n","        x = self.relu(self.fc(x))\n","        x = self.relu(self.fc2(x))\n","        return self.fc3(x)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T18:26:22.237220Z","iopub.status.busy":"2024-09-15T18:26:22.236351Z","iopub.status.idle":"2024-09-15T18:26:22.808466Z","shell.execute_reply":"2024-09-15T18:26:22.807526Z","shell.execute_reply.started":"2024-09-15T18:26:22.237180Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","\n","model = DistilBERTRegressor(output_dim=1)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","if torch.cuda.device_count() > 1:\n","    model = torch.nn.DataParallel(model)\n","model = model.to(device)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T18:26:22.944872Z","iopub.status.busy":"2024-09-15T18:26:22.944542Z","iopub.status.idle":"2024-09-15T18:26:22.949718Z","shell.execute_reply":"2024-09-15T18:26:22.948720Z","shell.execute_reply.started":"2024-09-15T18:26:22.944840Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["using cuda\n"]}],"source":["print(\"using\" , device)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T18:48:55.491017Z","iopub.status.busy":"2024-09-15T18:48:55.490652Z","iopub.status.idle":"2024-09-15T18:48:55.544824Z","shell.execute_reply":"2024-09-15T18:48:55.544052Z","shell.execute_reply.started":"2024-09-15T18:48:55.490983Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv('/kaggle/input/traindata/final_item_h.csv')\n","dataset = ItemDataset(df, tokenizer)\n","dataloader = DataLoader(dataset, batch_size=1, shuffle=True , num_workers=4)\n","\n","\n","learning_rate = 1e-2\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = ReduceLROnPlateau(optimizer,factor=0.7, patience=1)\n","criterion = nn.MSELoss()\n","\n"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T18:48:57.105628Z","iopub.status.busy":"2024-09-15T18:48:57.105228Z","iopub.status.idle":"2024-09-15T18:48:57.111545Z","shell.execute_reply":"2024-09-15T18:48:57.110562Z","shell.execute_reply.started":"2024-09-15T18:48:57.105571Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["23400\n","23400\n"]}],"source":["print(len(df))\n","print(len(dataloader))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T18:48:58.252952Z","iopub.status.busy":"2024-09-15T18:48:58.252304Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/1:   0%|          | 0/23400 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","Epoch 1/1:  25%|██▌       | 5910/23400 [04:45<13:46, 21.15batch/s]"]}],"source":["num_epochs = 1\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","    \n","    for batch in tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch'):\n","        optimizer.zero_grad()\n","\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        label = batch['label'].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        loss = criterion(outputs.squeeze(), label)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    avg_loss = total_loss / len(dataloader)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n","    \n","    scheduler.step(avg_loss)\n","\n","    \n","checkpoint = {'model_state_dict': model.state_dict()}\n","  \n","torch.save(checkpoint, 'distilbert_model.pth')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-09-15T18:37:11.109650Z","iopub.status.busy":"2024-09-15T18:37:11.108784Z","iopub.status.idle":"2024-09-15T18:37:11.114532Z","shell.execute_reply":"2024-09-15T18:37:11.113586Z","shell.execute_reply.started":"2024-09-15T18:37:11.109608Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Resuming learning rate: 0.01\n"]}],"source":["print(f\"Resuming learning rate: {optimizer.param_groups[0]['lr']}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# weights=\"/kaggle/working/distilbert_model.pth\"\n","# checkpoint = torch.load(weights, map_location=device)\n","# model.load_state_dict(checkpoint['model_state_dict'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5710271,"sourceId":9405692,"sourceType":"datasetVersion"}],"dockerImageVersionId":30763,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
